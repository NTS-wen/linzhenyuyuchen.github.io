---
layout:     post
title:      马氏距离
subtitle:   Mahalanobis Distance
date:       2020-05-10
author:     LZY
header-img: img/xiaohuangren.jpg
catalog: true
tags:
    - 度量学习
---

# 马氏距离

马氏距离是度量学习中一种常用的距离指标，同欧氏距离、曼哈顿距离、汉明距离等一样被用作评定数据之间的相似度指标。但却可以应对高维线性分布的数据中各维度间非独立同分布的问题。

# 定义

单数据点马氏距离

![](/img/vnn123.png)

其中beta是样本均值

S是样本集合的协方差矩阵

---

数据点x y的马氏距离

![](/img/vnn1234.png)

如果S是单位矩阵，也就是说各个维度独立同分布，那么马氏距离就退化为欧氏距离

# 实际意义

欧式距离在一些情况下不适用，比如身高和体重，这两个变量拥有不同的单位标准，也就是有不同的scale。比如身高用毫米计算，而体重用千克计算，显然差10mm的身高与差10kg的体重是完全不同的。但在普通的欧氏距离中，这将会算作相同的差距。

---

归一化后欧氏距离也有不可用的情况，举个一维的栗子，现在有两个类别，统一单位，第一个类别均值为0，方差为0.1，第二个类别均值为5，方差为5。那么一个值为2的点属于第一类的概率大还是第二类的概率大？距离上说应该是第一类，但是直觉上显然是第二类，因为第一类不太可能到达2这个位置。所以，在一个方差较小的维度下很小的差别就有可能成为离群点。

![](/img/11440w.jpg)

---

还有一个问题——如果维度间不独立同分布，样本点一定与欧氏距离近的样本点同类的概率更大吗？

![](/img/w476.png)

可以看到样本基本服从f(x) = x的线性分布，A与B相对于原点的距离依旧相等，显然A更像是一个离群点

即使数据已经经过了标准化，也不会改变AB与原点间距离大小的相互关系。所以要本质上解决这个问题，就要针对主成分分析中的主成分来进行标准化。


# 几何意义

马氏距离将变量按照主成分进行旋转，让维度间独立后再标准化，让维度独立同分布。由主成分分析可知，由于主成分就是特征向量方向，每个特征向量方向的方差就是对应的特征值，所以只需要按照特征向量的方向旋转，然后缩放特征值倍。这样就可以分离离群点，计算其欧氏距离。
