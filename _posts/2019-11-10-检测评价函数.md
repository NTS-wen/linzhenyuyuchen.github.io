---
layout:     post
title:      检测评价函数
subtitle:   intersection-over-union IOU
date:       2019-11-10
author:     LZY
header-img: img/whatisnext.jpg
catalog: true
tags:
    - 目标检测
    - 深度学习
---


# 检测评价函数


## 评价指标

### IoU

1. ground-truth bounding boxes

2. 训练好的模型预测得到的bounding boxes

`IoU = 二者重叠区域 / 并集区域`


```python
def bb_intersection_over_union(boxA, boxB):
   # determine the (x, y)-coordinates of the intersection rectangle
   # 画个图会很明显，x左、y上取大的，x右、y下取小的，刚好对应交集
   xA = max(boxA[0], boxB[0])
   yA = max(boxA[1], boxB[1])
   xB = min(boxA[2], boxB[2])
   yB = min(boxA[3], boxB[3])
 ​
   # compute the area of intersection rectangle
   # 计算交集部分面积
   interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)
 ​
   # compute the area of both the prediction and ground-truth rectangles
   # 计算预测值和真实值的面积
   boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)
   boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)
 ​
   # compute the intersection over union by taking the intersection
   # area and dividing it by the sum of prediction + ground-truth
   # areas - the interesection area
   # 计算IoU，即 交/（A+B-交）
   iou = interArea / float(boxAArea + boxBArea - interArea)
 ​
   # return the intersection over union value
   return iou
```

下面实现是batch的矩阵运算



```python
def bbox_overlaps(bboxes1, bboxes2, mode='iou'):
    """Calculate the ious between each bbox of bboxes1 and bboxes2.
    Args:
        bboxes1(ndarray): shape (n, 4)
        bboxes2(ndarray): shape (k, 4)
        mode(str): iou (intersection over union) or iof (intersection
            over foreground)
    Returns:
        ious(ndarray): shape (n, k)
    """

    assert mode in ['iou', 'iof']

    bboxes1 = bboxes1.astype(np.float32)
    bboxes2 = bboxes2.astype(np.float32)
    rows = bboxes1.shape[0]
    cols = bboxes2.shape[0]
    ious = np.zeros((rows, cols), dtype=np.float32)
    if rows * cols == 0:
        return ious
    exchange = False
    if bboxes1.shape[0] > bboxes2.shape[0]:
        bboxes1, bboxes2 = bboxes2, bboxes1
        ious = np.zeros((cols, rows), dtype=np.float32)
        exchange = True
    area1 = (bboxes1[:, 2] - bboxes1[:, 0] + 1) * (
        bboxes1[:, 3] - bboxes1[:, 1] + 1)
    area2 = (bboxes2[:, 2] - bboxes2[:, 0] + 1) * (
        bboxes2[:, 3] - bboxes2[:, 1] + 1)
    for i in range(bboxes1.shape[0]):
        x_start = np.maximum(bboxes1[i, 0], bboxes2[:, 0])
        y_start = np.maximum(bboxes1[i, 1], bboxes2[:, 1])
        x_end = np.minimum(bboxes1[i, 2], bboxes2[:, 2])
        y_end = np.minimum(bboxes1[i, 3], bboxes2[:, 3])
        overlap = np.maximum(x_end - x_start + 1, 0) * np.maximum(
            y_end - y_start + 1, 0)
        if mode == 'iou':
            union = area1[i] + area2 - overlap
        else:
            union = area1[i] if not exchange else area2
        ious[i, :] = overlap / union
    if exchange:
        ious = ious.T
    return ious
```

### mAP

mAP: mean Average Precision, 即各类别AP的平均值

- mAP: mean Average Precision, 即各类别AP的平均值。这个mean的意思是对每个类的AP再求平均，得到的就是mAP的值，mAP的大小一定在[0,1]区间，越大越好。该指标是目标检测算法中最重要的一个。在正样本非常少的情况下，PR表现的效果会更好。

- AP: Precision-recall 曲线下面的面积，其实是在0～1之间所有recall值的precision的平均值，通常来说一个越好的分类器，AP值越高。

- PR曲线: Precision-Recall曲线

- Precision: TP / (TP + FP)

- Recall: TP / (TP + FN)

- TP: IoU>Threshold的检测框数量（同一Ground Truth只计算一次）

- FP: IoU<=Threshold的检测框，或者是检测到同一个GT的多余检测框的数量

- FN: 没有检测到的GT的数量


### PR曲线和ROC曲线比较

#### ROC曲线特点：

1. 优点：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。因为TPR聚焦于正例，FPR聚焦于与负例，使其成为一个比较均衡的评估方法。

2. 在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。

3. 缺点：上文提到ROC曲线的优点是不会随着类别分布的改变而改变，但这在某种程度上也是其缺点。因为负例N增加了很多，而曲线却没变，这等于产生了大量FP。像信息检索中如果主要关心正例的预测准确性的话，这就不可接受了。在类别不平衡的背景下，负例的数目众多致使FPR的增长不明显，导致ROC曲线呈现一个过分乐观的效果估计。ROC曲线的横轴采用FPR，根据FPR ，当负例N的数量远超正例P时，FP的大幅增长只能换来FPR的微小改变。结果是虽然大量负例被错判成正例，在ROC曲线上却无法直观地看出来。（当然也可以只分析ROC曲线左边一小段）

#### PR曲线：

1. PR曲线使用了Precision，因此PR曲线的两个指标都聚焦于正例。类别不平衡问题中由于主要关心正例，所以在此情况下PR曲线被广泛认为优于ROC曲线。

2. ROC曲线由于兼顾正例与负例，所以适用于评估分类器的整体性能，相比而言PR曲线完全聚焦于正例。

3. 如果有多份数据且存在不同的类别分布，比如信用卡欺诈问题中每个月正例和负例的比例可能都不相同，这时候如果只想单纯地比较分类器的性能且剔除类别分布改变的影响，则ROC曲线比较适合，因为类别分布改变可能使得PR曲线发生变化时好时坏，这种时候难以进行模型比较；反之，如果想测试不同类别分布下对分类器的性能的影响，则PR曲线比较适合。

4. 如果想要评估在相同的类别分布下正例的预测情况，则宜选PR曲线。

5. 类别不平衡问题中，ROC曲线通常会给出一个乐观的效果估计，所以大部分时候还是PR曲线更好。

6. 最后可以根据具体的应用，在曲线上找到最优的点，得到相对应的precision，recall，f1 score等指标，去调整模型的阈值，从而得到一个符合具体应用的模型。




#### VOC采用两种不同方法采样PR曲线

mAP计算示例(两种VOC方式比较)
https://zhuanlan.zhihu.com/spectre
https://zhuanlan.zhihu.com/p/60319755

