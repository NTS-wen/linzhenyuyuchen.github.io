---
layout:     post
title:      生成对抗网络
subtitle:   Generative Adversarial Networks
date:       2019-12-14
author:     LZY
header-img: img/whatisnext.jpg
catalog: true
tags:
    - 深度学习
    - 生成对抗网络
    - GAN
---

[reference](https://www.jiqizhixin.com/articles/2019-03-19-12)

[Github Pytorch GAN](https://github.com/eriklindernoren/PyTorch-GAN)

# GAN

生成对抗网络的生成网络和判别网络互相对抗：生成网络尽可能生成逼真样本，判别网络则尽可能去判别该样本是真实样本，还是生成的假样本。

![](/img/2200640.png)

隐变量 z （通常为服从高斯分布的随机噪声）通过 Generator 生成 Xfake, 判别器负责判别输入的 data 是生成的样本 Xfake 还是真实样本 Xreal。优化的目标函数如下：

![](/img/2222640.png)

对于判别器 D 来说，这是一个二分类问题，V(D,G) 为二分类问题中常见的交叉熵损失。

对于生成器 G 来说，为了尽可能欺骗 D，所以需要最大化生成样本的判别概率 D(G(z))，即最小化 log(1-D(G(z)))，注意：log(D(x)) 一项与生成器 G 无关，所以可以忽略。其最小化的是 V(D,G) 的最大值

实际训练时，生成器和判别器采取交替训练，即先训练 D，然后训练 G，不断往复。

# 实践中的问题

GAN 的优化目标是一个极小极大（minmax）问题。
优化生成器的时候，最小化的是max(V(G,D)),要保证 V(G,D) 最大化，就需要迭代非常多次，这就导致训练时间很长。

如果我们只迭代一次判别器，然后迭代一次生成器，不断循环迭代。这样原先的极小极大问题，就容易变成极大极小（maxmin）问题，可二者是不一样的。

如果变化为极小极大问题，那么迭代就是这样的，生成器先生成一些样本，然后判别器给出错误的判别结果并惩罚生成器，于是生成器调整生成的概率分布。可是这样往往导致生成器变“懒”，只生成一些简单的，重复的样本，即缺乏多样性，也叫 mode collapse。

# 稳定GAN训练的技巧

`Feature matching`：方法很简单，使用判别器某一层的特征替换原始 GAN Loss 中的输出。即最小化：生成图片通过判别器的特征和真实图片通过判别器得到的特征之间的距离。 

`标签平滑`：GAN 训练中的标签非 0 即 1，这使得判别器预测出来的 confidence 倾向于更高的值。使用标签平滑可以缓解该问题。具体来说，就是把标签 1 替换为 0.8~1.0 之间的随机数。 


`PatchGAN`：准确来说 PatchGAN 并不是用于稳定训练，但这个技术被广泛用于图像翻译当中，PatchGAN 相当于对图像的每一个小 Patch 进行判别，这样可以使得生成器生成更加锐利清晰的边缘。

具体做法是这样的：假设输入一张 256x256 的图像到判别器，输出的是一个 4x4 的 confidence map，confidence map 中每一个像素值代表当前 patch 是真实图像的置信度，即为 PatchGAN。当前图像 patch 的大小就是感受野的大小，最后将所有 Patch 的 Loss 求平均作为最终的 Loss。

