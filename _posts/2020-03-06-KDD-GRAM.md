---
layout:     post
title:      KDD GRAM
subtitle:   Graph-based Attention Model for Healthcare
Representation Learning / Knowledge-Discovery in Databases
date:       2020-03-06
author:     LZY
header-img: img/xiaohuangren.jpg
catalog: true
tags:
    - 数据挖掘
    - KDD
---

# 介绍

![](/img/2020052701.png)

叶节点：EHR中的医学概念，数量为C

非叶节点：一般性概念

gi: ci 对应的 basic embedding ei,eg,ec,ea 和以注意力机制和注意力a结合

![](/img/2020052702.png)

G: 所有的gi组成

xt: 病人的某次记录 xt属于{0，1} 长度为C，即医学概念的数目

vt: xt和G计算而来 tanh(G xt) 作为神经网络的输入

# Q1 注意力机制的 a 是什么

注意力权重a是由Softmax计算而来；

![](/img/2020052703.png)

f(ei, ej )是一个标量，代表ei和ej的兼容性，用一个MLP单隐含层计算：

![](/img/2020052704.png)

# Q2 e 如何初始化

use `co-occurrence information` to initialize basic embeddings

```
Randomly initialize basic embedding matrix E

repeat
Update E with GloVe objective function (see Section 2.4)
until convergence
```

In our case, the co-occurrence matrix of the codes and the ancestors
was generated by counting the co-occurrences within each visit Vt, where we augment each visit with the
ancestors of the codes in the visit.

# End-to-End 训练

![](/img/2020052705.png)

# Loss函数

![](/img/2020052706.png)

