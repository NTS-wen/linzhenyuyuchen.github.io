---
layout:     post
title:      Pytorch 卷积神经网络特征图可视化
subtitle:   自定义网络
date:       2020-05-15
author:     LZY
header-img: img/xiaohuangren.jpg
catalog: true
tags:
    - 深度学习
    - Pytorch
---

# 卷积神经网络特征图可视化

[Reference](https://github.com/scutan90/CNN-Visualization/blob/master/CNN%E5%8F%AF%E8%A7%86%E5%8C%96.md)

- 使用图片块来可视化卷积核

- 通过特征重构出图像，将重构结果与原图进行比较来分析 CNN 的每一层保留了图像的哪些特征

- 类别激活映射（Class Activation Mapping，CAM）可视化方法，采用 NIN 和 GoogLeNet 中所用到的全局平均池化（Global Average Pooling，GAP），将卷积神经网络最后的全连接层换成全卷积层，并将输出层的权重反向投影至卷积层特征

- 在 CAM 的基础上提出了 Grad-CAM。CAM 通过替换全连接层为 GAP 层，重新训练得到权重，而 Grad-CAM 另辟蹊径，用梯度的全局平均来计算每对特征图对应的权重，最后求一个加权和。Grad-CAM 与 CAM 的主要区别在于求权重的过程




## 方法 1

> 通过反向计算，将低维度的特征图反向传播至原图像像素空间，观察特征图被原图的哪一部分激活，从而理解特征图从原图像中学习了何种特征。经典方法有反卷积(Deconvolution)[36]和导向反向传播(Guided-backpropagation)。这两种方法能够在一定程度上“看到”CNN 模型中较深的卷积层所学习到的特征。从本质上说，反卷积和导向反向传播的基础都是反向传播，即对输入进行求导。

[Grad CAM](https://linzhenyuyuchen.github.io/2020/01/31/Pytorch-Grad-CAM/)

## 方法 2

> 通过前向计算直接可视化深度卷积网络每一层的卷积核以及提取的特征图，然后观察其数值变化。一个训练成功的 CNN 网络，其特征图的值会伴随网络深度的加深而越来越稀疏。

```python
import matplotlib.pyplot as plt
from pylab import *

def get_row_col(num_pic):
    squr = num_pic ** 0.5
    row = round(squr)
    col = row + 1 if squr - row > 0 else row
    return row, col


def visualize_feature_map(img_batch):
    feature_map = img_batch
    print(feature_map.shape)
 
    feature_map_combination = []
    plt.figure()
 
    num_pic = feature_map.shape[2]
    row, col = get_row_col(num_pic)
    
    num_pic = min(num_pic,20)
    for i in range(0, num_pic):
        feature_map_split = feature_map[:, :, i]
        feature_map_combination.append(feature_map_split)
        plt.subplot(row, col, i + 1)
        plt.imshow(feature_map_split)
        axis('off')
 
    #plt.savefig('feature_map.png')
    plt.show()
 
    # 各个特征图按1：1 叠加
    feature_map_sum = sum(ele for ele in feature_map_combination)
    plt.imshow(feature_map_sum)
    #plt.savefig("feature_map_sum.png")
```

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import numpy as np
import cv2

model_resnet = models.resnet101(pretrained=True)
new_model = nn.Sequential(*list(model_resnet.children()))[:-2] 

img = cv2.imread("1.jpg")
inputs = torch.Tensor(np.array(img)).permute(2,0,1).unsqueeze(0)
out = new_model(inputs)
```

```python
feature = out.reshape(out.shape[1:])
feature = feature.permute(1,2,0)
visualize_feature_map(feature.detach().numpy())
```
