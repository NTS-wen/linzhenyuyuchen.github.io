---
layout:     post
title:      AutoML
subtitle:   automated machine learning
date:       2019-12-15
author:     LZY
header-img: img/whatisnext.jpg
catalog: true
tags:
    - 机器学习
    - 深度学习
---

# AutoML

AutoML是指尽量不通过人来设定超参数，而是使用某种学习机制，来调节这些超参数。这些学习机制包括传统的贝叶斯优化，多臂老虎机（multi-armed bandit），进化算法，还有比较新的强化学习。

- 传统AutoML: 自动调节传统的机器学习算法的参数，比如随机森林，调节它的max_depth, num_trees, criterion等参数。

- 深度AutoML: 与传统AutoML的差别是，现阶段深度AutoML，会将神经网络的超参数分为两类，一类是与训练有关的超参数，比如learning rate, regularization, momentum等; 还有一类超参数，则可以总结为网络结构。针对网络结构的自动调节Neural architecture search (NAS) 。针对训练的超参数，也是传统AutoML的自动调节，叫 Hyperparameter optimization (HO)。

# NAS

> 神经架构搜索

开发神经网络模型通常需要大量的模型工程，一般可以通过迁移学习快速搭建出一个"能用"的模型出来，但如果真的想要获得最佳性能，通常最好是根据具体任务设计自己的网络，这就需要专业的技能和大量的试验，并根据实验结果调整网络模型，整个实验本身耗时耗力，代价昂贵。

NAS是一种搜索最佳神经网络架构的算法。大多数模型算法都具有以下结构，首先定义一组可能用于我们网络的“构建块”。在NAS算法中，控制器递归神经网络（RNN）对这些构建块进行采样，将它们组合在一起以创建某种端到端模型。该体系结构通常体现出与最先进的网络（例如ResNets 或 DenseNets）相同的模型样式 ，只是使用的构建块有着差别或配置的方式不同罢了。

然后对这种新的网络架构进行训练以使得模型收敛，并在验证集上保持获得一些准确性，由此产生的精度可以用于更新控制器，以便控制器随着时间的推移产生更好的架构，可能选择出更好的构建块或更好的组合方式，使用策略梯度更新控制器权重。

## AutoKeras

>基于keras的自动化机器学习

Github: `https://github.com/keras-team/autokeras`

官方文档： `https://autokeras.com/`

自定义模型训练: `https://autokeras.com/tutorial/customized/`

支持的模型类别：用于分类的卷积神经网路（CNN）、循环神经网络（RNN）、长短期记忆网络（LSTM）

AutoKeras使用一个通过循环训练的 RNN 控制器，对候选架构（即子模型）进行采样，然后对其进行训练，以测量其在期望任务中的性能。接着，控制器使用性能作为指导信号，以找到更有前景的架构。

然而，神经架构搜索在计算上非常昂贵、耗时，例如 Zoph 等人在 2018 年发表的论文使用 450 个 GPU 运行了大约 4 万个 GPU 小时。

另一方面，使用更少的资源往往产生倾倒的结果。为了解决这个问题，AutoKeras使用了高效神经架构搜索（ENAS）。

ENAS 应用了一个类似于迁移学习的概念，其思想是：在特定任务上为特定模型学习的参数可以用于其他任务上的其他模型。因此，ENAS 迫使所有生成的子模型共享权值，从而刻意防止从头开始训练每一个子模型。这篇论文的作者表明，ENAS 不仅可以在子模型之间共享参数，还能够获得非常强的性能。

## Auto-sklearn

>基于sklearn的自动化机器学习

`https://github.com/automl/auto-sklearn`

支持的模型类别：分类、回归

Auto-sklean同时考虑选择一个学习算法和设置其超参数的问题，主要区别是将两个额外的步骤合并到主进程中：一开始是元学习步骤，最后是自动化集成构造步骤。

