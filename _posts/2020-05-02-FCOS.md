---
layout:     post
title:      FCOS
subtitle:   Fully Convolutional One-Stage Object Detection
date:       2020-05-02
author:     LZY
header-img: img/xiaohuangren.jpg
catalog: true
tags:
    - 目标检测
    - 图像分割
---

# FCOS

[arxiv](https://arxiv.org/abs/1904.01355)

## 全卷积一阶检测器

FCOS使用backbone CNN 提取特征，直接对feature map中每个位置(x,y)对应原图的边框都进行回归，如果(x,y)落入任何真实边框，则记为C=真实边框类别的正样本。否则记为负样本,C=0

FCOS训练C个二元分类器,C是类别数

## 使用FPN进行多级预测

![](/img/vnn11.png)

C3 C4 C5 是backbone生成的feature map

P3 P4 P5 是C3 C4 C5通过自上而下的上采样和1x1卷积层生成的，P4=P5两倍上采样+C4 P3=P4两倍上采样+C3

P6 P7 是P5 P6经过步长为2的1x1卷积层生成的

不同于anchor的检测器，将不同的anchor分配给不同特征级别。FCOS直接限制每个级别的bbox的回归范围。

---

![](/img/vnn97.png)

t∗= (l∗,t∗,r∗,b∗)

l∗,t∗,r∗,b∗ 分别是当前位置(x,y)到检测框边界的距离

![](/img/v422.png)

如果一个位置处于多个边框中，则记为模糊样本(ambiguous sample)

不同于anchor-base检测器将不同的anchor分配给不同特征级别，FCOS直接限制每个level边界框的范围

m(i)是feature level (i)的最大回归距离，分别设m2,m3,m4,m5,m6,m7为0,64,128,256,512, ∞,当max(l∗,t∗,r∗,b∗)> mi 或者 max(l∗,t∗,r∗,b∗)< m(i-1),该位置设为负样本，不需要回归。当一个位置在多个level中都在ground truth中，则选择最小面积的level作为目标。

---

FCOS在多个level间共享head参数，这样能极爱年少计算量并提升检测性能。

## Center-ness

### 问题

由于有些位置预测了离中心比较远的边界框，这产生了大量的低质量边框

FCOS提出了一种简单而有效的策略来抑制这些低质量的检测到的边界框，而无需引入任何超参数

IOU分数较低的被认为是低质量边框,一个bbox有较低的IOU和较高的score很容易成为fp，从而影响precision

### 解决方法

![](/img/vnn788.png)

在分类分支增加一个分支"center-ness",表示从该位置到中心点的距离,距离最近时为1，距离越远center-ness越小。也可以理解为样本所占权重

![](/img/v932.png)

sqrt是用来减慢center-ness的衰减，center-ness的范围是0～1，因此使用binary cross entropy (BCE) loss

### 效果

测试时，通过将预测的center-ness乘以相应的分类分数来计算最终分数（用于对检测到的边界框进行排名）。因此，center-ness可以降低远离对象中心的边界框的分数。 这些低质量的边界框很有可能通过最终的非极大值抑制（NMS）过程被滤除，从而显著提高了检测性能。


# Code

[github](https://github.com/tianzhi0549/FCOS/)

## build_backbone

- rennet.py

- fpn.py

实现backbone和fpn提取feature maps(P3-P7)

## build_rpn

- fcos.py

实现了头部共享，分类、回归、center-ness网络的搭建
